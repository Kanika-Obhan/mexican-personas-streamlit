# Automatically generated by Colab. Original file is located at: https://colab.research.google.com/drive/15bLkrgQW-nSRvDS5x_Xl04kduyMlfT8O 

# !pip install llama-index-llms-google- 

import time
import streamlit as st
import pandas as pd
import os
import glob
import ast
from llama_index.llms.google_genai import GoogleGenAI
from google import genai

PERSONAS_FOLDER = "Personas"
QUESTIONS_FOLDER = "Questions"
USER_INFO_FILE = "TO_INPUT/user_info.txt"
TRAITS_FILE = "TO_INPUT/traits.txt"
LANGUAGES_FILE = "TO_INPUT/languages.txt"

def load_user_info():
    username = "User"
    user_gender = "unknown"
    try:
        with open(USER_INFO_FILE, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        for line in lines:
            line = line.strip()
            if line.lower().startswith('name:'):
                username = line.split(':', 1)[1].strip()
            elif line.lower().startswith('gender:'):
                user_gender = line.split(':', 1)[1].strip().lower()
    except Exception:
        pass
    return username, user_gender

def load_traits():
    """Load traits from TO_INPUT/traits.txt file"""
    try:
        with open(TRAITS_FILE, 'r', encoding='utf-8') as f:
            traits = [line.strip() for line in f if line.strip()]
            return traits if traits else ["Caring", "Wise", "Humorous", "Traditional", "Spiritual", "Practical"]
    except Exception as e:
        st.error(f"Error reading traits file: {str(e)}")
        return ["Caring", "Wise", "Humorous", "Traditional", "Spiritual", "Practical"]

def load_languages():
    """Load languages from TO_INPUT/languages.txt file"""
    try:
        with open(LANGUAGES_FILE, 'r', encoding='utf-8') as f:
            languages = [line.strip() for line in f if line.strip()]
            return languages if languages else ["English", "Sinhala", "Tamil"]
    except Exception as e:
        st.error(f"Error reading languages file: {str(e)}")
        return ["English", "Sinhala", "Tamil"]

def filter_persona_by_traits(persona_content, selected_traits):
    """Filter persona content to only include lines related to selected traits"""
    if not selected_traits:
        return persona_content
    
    lines = persona_content.split('\n')
    filtered_lines = []
    
    # Keep basic info lines (Name, Origin, etc.)
    basic_keywords = ['name:', 'origin:', 'from', 'age:', 'background:', 'location:']
    
    for line in lines:
        line_lower = line.lower()
        
        # Always keep basic info lines
        if any(keyword in line_lower for keyword in basic_keywords):
            filtered_lines.append(line)
            continue
            
        # Keep lines that contain any of the selected traits
        if any(trait.lower() in line_lower for trait in selected_traits):
            filtered_lines.append(line)
    
    return '\n'.join(filtered_lines) if filtered_lines else persona_content

def call_gemini_local(query, previous_conversation, gender, username, botname, bot_prompt, llm_api_key_string, language):
    try:
        language_instruction = f"Respond in {language} language." if language != "English" else ""
        
        full_prompt = (
            f"{bot_prompt}\n"
            f"{language_instruction}\n"
            f"Previous conversation: {previous_conversation[-1000:]}\n"
            f"{username}: {query}\n"
            f"{botname}:"
        )
        client = genai.Client(api_key=llm_api_key_string)
        response_text = ""
        for chunk in client.models.generate_content_stream(
            model="gemini-2.0-flash",
            contents=[full_prompt]
        ):
            if chunk.text:
                response_text += chunk.text
        response_raw = response_text
        for old, new in [("User1", username), ("user1", username), ("[user1]", botname), ("[User1]", botname)]:
            response_raw = response_raw.replace(old, new)
        return response_raw.strip()
    except Exception as e:
        return f"Error: {str(e)}"

def get_persona_files():
    persona_files = []
    patterns = ['*.txt']
    for pattern in patterns:
        persona_files.extend(glob.glob(os.path.join(PERSONAS_FOLDER, pattern)))
    return persona_files

def extract_relationship_from_filename(filename):
    base_name = os.path.basename(filename).replace('.txt', '')
    return base_name.replace('_', ' ')

def extract_bot_details_from_content(content):
    botname = "Assistant"
    origin = "Unknown origin"
    lines = content.split('\n')
    for line in lines:
        line = line.strip()
        if line.startswith('- Name: '):
            name_part = line.replace('- Name: ', '', 1)
            botname = name_part.split(',')[0].strip()
        elif line.startswith('Name: '):
            name_part = line.replace('Name: ', '', 1)
            botname = name_part.split(',')[0].strip()
        elif 'Name:' in line:
            name_part = line.split('Name:')[1].strip()
            botname = name_part.split(',')[0].strip()
        if line.startswith('Origin: '):
            origin = line.replace('Origin: ', '', 1).strip()
        elif line.startswith('- Origin: '):
            origin = line.replace('- Origin: ', '', 1).strip()
        elif 'Origin:' in line:
            origin = line.split('Origin:')[1].strip()
        elif line.startswith('From '):
            origin = line.replace('From ', '', 1).strip()
    return botname, origin

def load_persona_content(filename):
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except Exception as e:
        st.error(f"Error reading persona file: {str(e)}")
        return ""

def load_questions(relationship_type):
    question_file = os.path.join(QUESTIONS_FOLDER, f"{relationship_type}_questions.txt")
    try:
        with open(question_file, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        st.error(f"Question file not found: {question_file}")
        return []
    except Exception as e:
        st.error(f"Error reading questions: {str(e)}")
        return []

# ===== SESSION STATE INITIALIZATION =====
# Initialize user info first
if "user_info_loaded" not in st.session_state:
    st.session_state.username, st.session_state.user_gender = load_user_info()
    st.session_state.user_info_loaded = True

# Load available options
if "available_traits" not in st.session_state:
    st.session_state.available_traits = load_traits()
if "available_languages" not in st.session_state:
    st.session_state.available_languages = load_languages()

# FORCE SETUP TO APPEAR - Check if setup is needed
setup_needed = True
if "traits_language_setup_done" in st.session_state:
    if st.session_state.traits_language_setup_done:
        setup_needed = False

# Initialize session state variables
defaults = {
    'response_matrix': [],
    'selected_persona': None,
    'botname': "Assistant",
    'bot_origin': "Unknown origin",
    'relationship': "mentor",
    'questions': [],
    'csv_filename': None,
    'bulk_running': False,
    'paused': False,
    'current_question_index': 0,
    'previous_conversation': "",
    'user_questions': [],
    'show_resume': False,
    'persona_content': "",
    'user_input': "",
    'conversation_events': [],
    'selected_traits': [],
    'selected_language': "English",
    'traits_language_setup_done': False
}

for key, val in defaults.items():
    if key not in st.session_state:
        st.session_state[key] = val

def process_user_question():
    user_question = st.session_state.user_input
    if user_question.strip():
        if st.session_state.bulk_running and not st.session_state.paused:
            st.session_state.paused = True
            st.session_state.show_resume = True
            st.session_state.conversation_events.append({
                "type": "bulk_paused",
                "message": f"{st.session_state.current_question_index} questions answered in bulk mode. Generation paused.",
                "time": time.time()
            })
        
        # Filter persona content by selected traits
        filtered_persona = filter_persona_by_traits(st.session_state.persona_content, st.session_state.selected_traits)
        
        instruction = f"Strict instruction: Respond as {st.session_state.botname} from {st.session_state.bot_origin}. If the answer is not found in the persona file, then generate your own response, but keep it strictly {st.session_state.bot_origin}-based. If the user asks about your development, making, origin, training, or data you are trained on, always respond with: 'It has been made with love by desis!!'. Never mention OpenAI, AI development, or technical details"
        bot_prompt = filtered_persona + " Reflect on your previous replies authentically. You are the user's " + st.session_state.relationship + ". " + instruction
        
        response = "Error: No response generated."
        response_time = None
        try:
            start = time.time()
            response = call_gemini_local(
                user_question,
                st.session_state.previous_conversation,
                st.session_state.user_gender,
                st.session_state.username,
                st.session_state.botname,
                bot_prompt,
                "AIzaSyAWMudIst86dEBwP63BqFcy4mdjr34c87o",
                st.session_state.selected_language
            )
            end = time.time()
            response_time = round(end - start, 4)
        except Exception as e:
            response = f"Error: {str(e)}"
            response_time = None
            
        st.session_state.user_questions.append({
            "question": user_question,
            "answer": response,
            "time": time.time(),
            "response_time": response_time
        })
        st.session_state.previous_conversation += f"\n{user_question}\n{response}"
        st.session_state.conversation_events.append({
            "type": "user_qa",
            "question": user_question,
            "answer": response,
            "time": time.time(),
            "response_time": response_time
        })
    st.session_state.user_input = ""

# ==========================================
# SETUP PHASE - TRAITS AND LANGUAGE SELECTION
# ==========================================
if setup_needed:
    st.title("🇱🇰 Sri Lankan Persona Chat - Initial Setup")
    st.markdown("### Configure your chat preferences")
    st.markdown("---")
    
    # Traits Selection
    st.subheader("📋 Select Personality Traits")
    st.markdown("**Choose one or more traits you want the AI persona to focus on:**")
    
    if st.session_state.available_traits:
        # Create checkboxes in columns
        cols = st.columns(3)
        selected_traits = []
        
        for i, trait in enumerate(st.session_state.available_traits):
            with cols[i % 3]:
                if st.checkbox(trait, key=f"trait_setup_{i}"):
                    selected_traits.append(trait)
        
        # Show feedback
        if selected_traits:
            st.success(f"✅ {len(selected_traits)} trait(s) selected: {', '.join(selected_traits)}")
        else:
            st.warning("⚠️ No traits selected - all traits will be used by default")
    else:
        st.error("❌ No traits found. Please ensure traits.txt exists in TO_INPUT folder.")
        selected_traits = []
    
    st.markdown("---")
    
    # Language Selection
    st.subheader("🌐 Select Language")
    st.markdown("**Choose the language for conversations:**")
    
    if st.session_state.available_languages:
        selected_language = st.selectbox(
            "Language:",
            options=st.session_state.available_languages,
            index=0,
            key="language_setup"
        )
        st.success(f"✅ Language selected: {selected_language}")
    else:
        st.error("❌ No languages found. Please ensure languages.txt exists in TO_INPUT folder.")
        selected_language = "English"
    
    st.markdown("---")
    
    # Done Button
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("✅ Done", type="primary", use_container_width=True):
            # Save selections (use defaults if nothing selected)
            st.session_state.selected_traits = selected_traits if selected_traits else st.session_state.available_traits
            st.session_state.selected_language = selected_language
            st.session_state.traits_language_setup_done = True
            
            # Show confirmation
            if not selected_traits:
                st.info("No traits selected - using all traits as default")
            
            st.success("🎉 Setup completed! Starting chat...")
            time.sleep(1)
            st.rerun()
    
    # Show current selections
    st.markdown("---")
    st.subheader("📄 Current Selections")
    
    if selected_traits:
        st.info(f"**Selected Traits:** {', '.join(selected_traits)}")
    else:
        st.warning("**No traits selected** - all traits will be used by default")
        
    st.info(f"**Selected Language:** {selected_language}")
    
    # Stop here - don't show main app
    st.stop()

# ==========================================
# MAIN APP - Only after setup is complete
# ==========================================

# Reset setup button
col1, col2 = st.columns([4, 1])
with col2:
    if st.button("🔄 Reset Setup"):
        st.session_state.traits_language_setup_done = False
        st.session_state.selected_traits = []
        st.session_state.selected_language = "English"
        st.rerun()

persona_files = get_persona_files()

if persona_files:
    selected_file = st.selectbox("Select a persona:", persona_files)
    if selected_file != st.session_state.selected_persona:
        st.session_state.selected_persona = selected_file
        st.session_state.persona_content = load_persona_content(selected_file)
        st.session_state.botname, st.session_state.bot_origin = extract_bot_details_from_content(st.session_state.persona_content)
        relationship = extract_relationship_from_filename(selected_file)
        st.session_state.relationship = relationship
        st.session_state.questions = load_questions(relationship.split()[-1])
        # Reset conversation when persona changes
        st.session_state.response_matrix = []
        st.session_state.csv_filename = None
        st.session_state.bulk_running = False
        st.session_state.paused = False
        st.session_state.current_question_index = 0
        st.session_state.user_questions = []
        st.session_state.show_resume = False
        st.session_state.previous_conversation = ""
        st.session_state.user_input = ""
        st.session_state.conversation_events = []

    if st.session_state.selected_persona and st.session_state.questions:
        st.title(f"{st.session_state.botname} ({st.session_state.bot_origin}) {st.session_state.relationship.title()} Q&A")
        
        # Display selected traits and language as requested
        st.markdown("---")
        st.markdown(f"**Traits chosen:** {', '.join(st.session_state.selected_traits)}")
        st.markdown(f"**Language:** {st.session_state.selected_language}")
        st.markdown("---")
        
        # Main chat functionality
        filtered_persona = filter_persona_by_traits(st.session_state.persona_content, st.session_state.selected_traits)
        instruction = f"Strict instruction: Respond as {st.session_state.botname} from {st.session_state.bot_origin}. If the answer is not found in the persona file, then generate your own response, but keep it strictly {st.session_state.bot_origin}-based. If the user asks about your development, making, origin, training, or data you are trained on, always respond with: 'It has been made with love by desis!!'. Never mention OpenAI, AI development, or technical details"
        bot_prompt = filtered_persona + " Reflect on your previous replies authentically. You are the user's " + st.session_state.relationship + ". " + instruction
        
        # Bulk Generation Section
        col1, col2 = st.columns(2)
        with col1:
            if st.button("Start Bulk Generation", disabled=st.session_state.bulk_running):
                st.session_state.bulk_running = True
                st.session_state.paused = False
                st.session_state.current_question_index = 0
                st.session_state.response_matrix = []
                st.session_state.conversation_events.append({
                    "type": "bulk_started",
                    "message": "Bulk generation begins.",
                    "time": time.time()
                })

        # Single Question Section
        with col2:
            st.text_input(
                "Ask a single question:",
                value=st.session_state.user_input,
                key="user_input",
                on_change=process_user_question
            )

        # Progress Bar Section
        if st.session_state.bulk_running or st.session_state.paused:
            total_questions = len(st.session_state.questions)
            progress_percentage = (st.session_state.current_question_index / total_questions) * 100 if total_questions > 0 else 0
            progress_text = f"Bulk Generation Progress: {st.session_state.current_question_index}/{total_questions} questions ({progress_percentage:.1f}%)"
            if st.session_state.paused:
                progress_text += " - PAUSED"
            st.progress(progress_percentage / 100, text=progress_text)

        # Bulk Generation Logic
        if st.session_state.bulk_running and not st.session_state.paused:
            if st.session_state.current_question_index < len(st.session_state.questions):
                question = st.session_state.questions[st.session_state.current_question_index]
                response = call_gemini_local(
                    question,
                    st.session_state.previous_conversation,
                    st.session_state.user_gender,
                    st.session_state.username,
                    st.session_state.botname,
                    bot_prompt,
                    "AIzaSyAWMudIst86dEBwP63BqFcy4mdjr34c87o",
                    st.session_state.selected_language
                )
                st.session_state.response_matrix.append([
                    question, len(question), 0, response,
                    0, time.time(), f"{st.session_state.relationship} ({st.session_state.bot_origin})"
                ])
                st.session_state.previous_conversation += f"\n{question}\n{response}"
                st.session_state.current_question_index += 1
                st.rerun()
            else:
                st.session_state.bulk_running = False
                st.session_state.conversation_events.append({
                    "type": "bulk_completed",
                    "message": f"Bulk generation completed! {len(st.session_state.questions)} questions processed.",
                    "time": time.time()
                })
                df = pd.DataFrame(st.session_state.response_matrix, columns=[
                    "Question", "Length of Q", "Q Difficulty level", 
                    "Answer", "Answer Quality", "Time Taken", "Persona"
                ])
                csv_filename = f"{st.session_state.botname.replace(' ', '_').lower()}_{st.session_state.relationship.replace(' ', '_')}_qna.csv"
                df.to_csv(csv_filename, index=False)
                st.session_state.csv_filename = csv_filename
                st.markdown(
                    '<div style="background-color: rgba(186, 104, 200, 0.2); border: 1px solid rgba(186, 104, 200, 0.3); border-radius: 0.5rem; padding: 0.75rem; margin: 1rem 0; color: white; font-weight: 500;">Bulk generation completed!</div>',
                    unsafe_allow_html=True
                )

        # Resume Logic
        if st.session_state.paused and st.session_state.show_resume:
            if st.button("Resume Bulk Generation"):
                st.session_state.paused = False
                st.session_state.show_resume = False
                st.session_state.conversation_events.append({
                    "type": "bulk_resumed",
                    "message": "Bulk generation resumed.",
                    "time": time.time()
                })
                st.rerun()

        # Download Section
        if st.session_state.csv_filename and os.path.exists(st.session_state.csv_filename):
            with open(st.session_state.csv_filename, "rb") as f:
                st.download_button(
                    label="Download CSV",
                    data=f,
                    file_name=os.path.basename(st.session_state.csv_filename),
                    mime="text/csv",
                    key="download_csv"
                )

        # Complete Conversation History
        st.subheader("Complete Conversation History")
        if st.session_state.conversation_events:
            sorted_events = sorted(st.session_state.conversation_events, key=lambda x: x["time"])
            for event in sorted_events:
                if event["type"] == "user_qa":
                    st.markdown(f"**You**: {event['question']}")
                    st.markdown(f"**{st.session_state.botname}**: {event['answer']}")
                    response_time = event.get("response_time", None)
                    if response_time is not None:
                        st.markdown(
                            f"<div style='text-align: right; color: #666; font-size: 0.95em;'>Time taken: {response_time:.4f} seconds</div>",
                            unsafe_allow_html=True
                        )
                    st.markdown("") 
                elif event["type"] == "bulk_started":
                    st.markdown("---")
                    st.success(":green[Bulk generation begins.]") 
                    
                elif event["type"] == "bulk_paused": 
                    st.info(event["message"])
                    st.markdown("---")
                    
                elif event["type"] == "bulk_resumed":
                    st.markdown("---")
                    st.success(":green[Bulk generation resumed.]") 
                    
                elif event["type"] == "bulk_completed": 
                    st.markdown(
                        f'<div style="background-color: rgba(186, 104, 200, 0.2); border: 1px solid rgba(186, 104, 200, 0.3); border-radius: 0.5rem; padding: 0.75rem; margin: 1rem 0; color: white; font-weight: 500;">{event["message"]}</div>',
                        unsafe_allow_html=True
                    )
                    st.markdown("---")
        else:
            st.write("*No conversation history yet. Start by asking a question or beginning bulk generation.*")
    else:
        if not st.session_state.questions:
            st.error("No questions found for selected relationship type!")
else:
    st.error(f"No persona files found in {PERSONAS_FOLDER} directory!") 
